#!/usr/bin/env python

import os
import threading
import pathlib
import logging
import sys
import time
import argparse
from queue import Queue
from workers.copyworker import FileCopyMessage, FileCopyWorker
from workers.filewritter import FileWritterWorker, FileWritterMessage
from workers.checksum_match import ChecksumWorker, ChecksumMessage
from progress.bar import Bar
from progress.spinner import Spinner

logger = logging.getLogger(__name__)


def configure_logging(dst_dir=None):
    handlers = []
    # handlers.append(logging.StreamHandler(sys.stdout))
    fpath = "copytool.log"
    if dst_dir:
        fpath = os.path.join(dst_dir, fpath)
    handlers.append(logging.FileHandler(fpath, 'w'))
    logging.basicConfig(handlers=handlers, level=logging.WARNING,
                        style='{', format="{asctime} | {levelname} | {name} | {module} | {message}")


def run_copy_tool(args):
    log_queue = Queue()
    work_queue = Queue()
    end = threading.Event()
    filewritter = FileWritterWorker(log_queue, end)

    original_dir = os.getcwd()

    src_dir = args.copy[0]
    dst_dir = args.copy[1]

    if not os.path.isabs(src_dir):
        src_dir = os.path.join(original_dir, src_dir)
    if not os.path.isabs(dst_dir):
        dst_dir = os.path.join(original_dir, dst_dir)
    if not os.path.isdir(dst_dir):
        pathlib.Path(dst_dir).mkdir(parents=True)

    configure_logging(dst_dir)

    checksum_file = os.path.join(dst_dir, args.checksum_file)
    csv_file = os.path.join(dst_dir, "summary.csv")
    log_queue.put(FileWritterMessage(csv_file, "filename,checksum\n"))

    workers = [FileCopyWorker(args.cksum, checksum_file, csv_file, args.full_copy, work_queue, log_queue,
                              end, name=f"copyworker-{i}") for i in range(args.workers)]

    for worker in workers:
        worker.start()
    filewritter.start()

    spinner = Spinner("Determining number of files to copy...")
    nfiles = 0
    for dirpath, dirnames, filenames in os.walk(src_dir):
        rel_path = os.path.relpath(dirpath, src_dir)
        rel_path = os.path.join(dst_dir, rel_path)
        for f in filenames:
            src = os.path.join(dirpath, f)
            dst = os.path.join(rel_path, f)
            message = FileCopyMessage(src, dst)

            if os.path.exists(message.dst):
                stat_src = os.lstat(message.src)
                stat_dst = os.lstat(message.dst)
                if stat_src.st_mtime_ns <= stat_dst.st_mtime_ns:
                    continue
            work_queue.put(message)
            nfiles += 1
        spinner.next()
    spinner.finish()

    if nfiles > 0:
        # clear line
        # print("\x1b[2K\r", end='', flush=True)
        bar = Bar("Copying files...", max=nfiles)
        qsize = work_queue.qsize()
        while qsize > 0:
            n = nfiles - qsize
            n = n - bar.index
            bar.next(n)
            time.sleep(1)
            qsize = work_queue.qsize()

        bar.finish()
    else:
        logger.info("no files to copy")

    work_queue.join()
    log_queue.join()
    end.set()
    for worker in workers:
        worker.join()
    filewritter.join()


def run_check_tool(args):
    work_queue = Queue()
    end = threading.Event()

    workdir = args.check
    if not os.path.isabs(workdir):
        workdir = os.path.join(os.getcwd(), workdir)
    configure_logging(workdir)
    checksum_file = os.path.join(workdir, args.checksum_file)
    if not os.path.exists(checksum_file):
        logger.critical(f"Checksum file {checksum_file} doesn't exist")
        sys.exit(1)

    workers = [ChecksumWorker(
        args.cksum, workdir, work_queue, end, name=f"checksumworker-{i}") for i in range(args.workers)]

    for worker in workers:
        worker.start()

    nfiles = 0
    with open(checksum_file, "r") as f:
        lines = f.readlines()
        nfiles = len(lines)
        for line in lines:
            work_queue.put(ChecksumMessage(line))

    bar = Bar("Checking files...", max=nfiles)
    qsize = work_queue.qsize()
    while qsize > 0:
        n = nfiles - qsize
        n = n - bar.index
        bar.next(n)
        qsize = work_queue.qsize()
    bar.finish()

    work_queue.join()
    end.set()
    for worker in workers:
        worker.join()


if __name__ == "__main__":

    parser = argparse.ArgumentParser()
    workertype_group = parser.add_mutually_exclusive_group(required=True)
    workertype_group.add_argument("--copy", nargs=2, metavar=('src', 'dst'),
                                  help="Copy mode. Copy the directory src to dst. The checksum is checked before and after copying each file to make sure it was successfully copied. Save checksum files in dst to be used with --check later. Produces a logfile in the current directory")
    workertype_group.add_argument(
        "--check", metavar='dir', help="Check mode. Verify that each file in the specified directory (and subdirectories) still match it's checksum. Each directory should have a checksum.sha3 file with the checksum of each file. Produces a logfile in the current directory")
    parser.add_argument("--full-copy", action="store_true", help="By default the script doesn't copy files if the destination already exists and was modified after src. Set this argument to copy every file regardless")
    parser.add_argument("--workers", default=os.cpu_count() * 5, type=int,
                        help="Number of workers (threads) to use. Default to the number of cpu cores")
    parser.add_argument("--cksum", choices=['sha384', 'sha1', 'blake2s', 'md5', 'sha3_256', 'sha224',
                                            'blake2b', 'sha512', 'sha3_384', 'sha256', 'sha3_224', 'sha3_512'], default="sha512", help="Select the checksum algorithm to use")
    args = parser.parse_args()
    args.checksum_file = f"checksum.{args.cksum}"
    if args.copy:
        run_copy_tool(args)
    elif args.check:
        run_check_tool(args)
