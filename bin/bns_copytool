#!/usr/bin/env python

import os
import threading
import pathlib
import logging
import sys
import argparse
from queue import Queue
from workers.copyworker import FileCopyMessage, FileCopyWorker
from workers.filewritter import FileWritterWorker
from workers.checksum_match import ChecksumWorker, ChecksumMessage
from progress.bar import Bar

logger = logging.getLogger(__name__)


def configure_logging():
    handlers = []
    # handlers.append(logging.StreamHandler(sys.stdout))
    handlers.append(logging.FileHandler('copytool.log', 'w'))
    logging.basicConfig(handlers=handlers, level=logging.WARNING,
                        style='{', format="{asctime} | {levelname} | {name} | {module} | {message}")


def run_copy_tool(args):
    log_queue = Queue()
    work_queue = Queue()
    end = threading.Event()
    filewritter = FileWritterWorker(log_queue, end)

    original_dir = os.getcwd()

    src_dir = args.copy[0]
    dst_dir = args.copy[1]

    if not os.path.isabs(src_dir):
        src_dir = os.path.join(original_dir, src_dir)
    if not os.path.isabs(dst_dir):
        dst_dir = os.path.join(original_dir, dst_dir)
    if not os.path.isdir(dst_dir):
        pathlib.Path(dst_dir).mkdir(parents=True)

    checksum_file = os.path.join(dst_dir, args.checksum_file)

    workers = [FileCopyWorker(args.cksum, checksum_file, work_queue, log_queue,
                              end, name=f"copyworker-{i}") for i in range(args.workers)]

    for worker in workers:
        worker.start()
    filewritter.start()

    print("Determining number of files to copy...", end='', flush=True)
    nfiles = 0
    for dirpath, dirnames, filenames in os.walk(src_dir):
        rel_path = os.path.relpath(dirpath, src_dir)
        for f in filenames:
            src = os.path.join(dirpath, f)
            dst = os.path.join(dst_dir, rel_path, f)
            work_queue.put(FileCopyMessage(src, dst))
            nfiles += 1
    print("\x1b[2K\r", end='', flush=True)
    bar = Bar("Copying files...", max=nfiles)
    qsize = work_queue.qsize()
    while qsize > 0:
        n = nfiles - qsize
        n = n - bar.index
        bar.next(n)
        qsize = work_queue.qsize()
    bar.finish()

    work_queue.join()
    log_queue.join()
    end.set()
    for worker in workers:
        worker.join()
    filewritter.join()


def run_check_tool(args):
    work_queue = Queue()
    end = threading.Event()

    workdir = args.check
    if not os.path.isabs(workdir):
        workdir = os.path.join(os.getcwd(), workdir)

    checksum_file = os.path.join(workdir, args.checksum_file)
    if not os.path.exists(checksum_file):
        logger.critical(f"Checksum file {checksum_file} doesn't exist")
        sys.exit(1)

    workers = [ChecksumWorker(
        args.cksum, workdir, work_queue, end, name=f"checksumworker-{i}") for i in range(args.workers)]

    for worker in workers:
        worker.start()

    nfiles = 0
    with open(checksum_file, "r") as f:
        lines = f.readlines()
        nfiles = len(lines)
        for line in lines:
            work_queue.put(ChecksumMessage(line))

    bar = Bar("Checking files...", max=nfiles)
    qsize = work_queue.qsize()
    while qsize > 0:
        n = nfiles - qsize
        n = n - bar.index
        bar.next(n)
        qsize = work_queue.qsize()
    bar.finish()

    work_queue.join()
    end.set()
    for worker in workers:
        worker.join()


if __name__ == "__main__":

    configure_logging()

    parser = argparse.ArgumentParser()
    workertype_group = parser.add_mutually_exclusive_group(required=True)
    workertype_group.add_argument("--copy", nargs=2, metavar=('src', 'dst'),
                                  help="Copy mode. Copy the directory src to dst. The checksum is checked before and after copying each file to make sure it was successfully copied. Save checksum files in dst to be used with --check later. Produces a logfile in the current directory")
    workertype_group.add_argument(
        "--check", metavar='dir', help="Check mode. Verify that each file in the specified directory (and subdirectories) still match it's checksum. Each directory should have a checksum.sha3 file with the checksum of each file. Produces a logfile in the current directory")
    parser.add_argument("--workers", default=os.cpu_count() * 5,
                        help="Number of workers to use. Default to the number of cpu cores")
    parser.add_argument("--cksum", choices=['sha384', 'sha1', 'blake2s', 'md5', 'sha3_256', 'sha224', 'blake2b', 'sha512', 'sha3_384', 'sha256', 'sha3_224', 'sha3_512'], default="sha512")
    args = parser.parse_args()

    args.checksum_file = f"checksum.{args.cksum}"

    if args.copy:
        run_copy_tool(args)
    elif args.check:
        run_check_tool(args)
